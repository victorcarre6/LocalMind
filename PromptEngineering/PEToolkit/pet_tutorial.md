# Tutorial : Ma√Ætriser le Prompt Engineering Toolkit (PET)

## Introduction

Ce tutorial vous guide √©tape par √©tape dans l'utilisation du Prompt Engineering Toolkit (PET). Nous progresserons du niveau d√©butant au niveau expert avec des exemples concrets et pratiques.

## Pr√©requis

```python
# Assurez-vous d'avoir le module PromptToolkit.py dans votre r√©pertoire
from PromptToolkit import *
```

---

## üü¢ NIVEAU 1 : LES BASES - Cr√©er son premier prompt

### 1.1 Construction manuelle simple

**Objectif** : Cr√©er un prompt basique pour r√©sumer un article

```python
def niveau_1_prompt_basique():
    """Exemple le plus simple : cr√©ation directe d'un prompt"""
    
    # Cr√©ation manuelle d'un prompt
    mon_prompt = Prompt(
        instruction="R√©sumez l'article suivant en 3 points cl√©s",
        context="Article de presse √©conomique sur l'intelligence artificielle",
        constraints=["Maximum 100 mots", "Utiliser des puces", "Langage accessible"]
    )
    
    # Ajout d'un exemple
    mon_prompt.add_example("Article sur crypto -> R√©sum√©: ‚Ä¢ Prix volatil ‚Ä¢ Adoption croissante ‚Ä¢ R√©gulation incertaine")
    
    print("=== PROMPT BASIQUE ===")
    print(mon_prompt.format())
    print(f"Valide: {mon_prompt.validate()}")
    
    return mon_prompt
```

**üí° Points cl√©s √† retenir :**
- La classe `Prompt` encapsule tous les √©l√©ments
- `add_example()` et `add_constraint()` enrichissent le prompt
- `validate()` v√©rifie la qualit√©
- `format()` g√©n√®re le prompt final pr√™t √† utiliser

### 1.2 Utilisation d'un template simple

**Objectif** : Utiliser un template pr√©d√©fini

```python
def niveau_1_avec_template():
    """Utilisation d'un template classification simple"""
    
    # Template pr√™t √† l'emploi
    classifieur_sentiment = classification_template(
        categories=["Positif", "Neutre", "N√©gatif"],
        description="Classification de commentaires clients sur un produit",
        examples=[
            ("Ce produit est fantastique, je le recommande!", "Positif"),
            ("Livraison correcte, rien d'exceptionnel", "Neutre"),
            ("Service client d√©cevant, je ne rach√®terai pas", "N√©gatif")
        ]
    )
    
    print("=== TEMPLATE CLASSIFICATION ===")
    print(classifieur_sentiment.format())
    
    return classifieur_sentiment
```

**üí° Ce que vous apprenez :**
- Les templates acc√©l√®rent le d√©veloppement
- Ils int√®grent les bonnes pratiques automatiquement
- Les exemples sont format√©s correctement

---

## üü° NIVEAU 2 : TRANSFORMATIONS - Am√©liorer ses prompts

### 2.1 Transformation simple

**Objectif** : Modifier un prompt existant avec une transformation

```python
def niveau_2_transformation_simple():
    """Application d'une transformation simple"""
    
    # Prompt de base
    prompt_base = Prompt(
        instruction="Expliquez ce concept technique √† un d√©butant",
        context="Concept: Les microservices en architecture logicielle"
    )
    
    # Application d'une transformation
    prompt_formel = make_formal(prompt_base)
    
    print("=== AVANT TRANSFORMATION ===")
    print(prompt_base.format())
    
    print("\n=== APR√àS TRANSFORMATION (formal) ===")  
    print(prompt_formel.format())
    
    # Comparaison
    print(f"\nPrompt original valide: {prompt_base.validate()}")
    print(f"Prompt transform√© valide: {prompt_formel.validate()}")
    
    return prompt_base, prompt_formel
```

### 2.2 Pipeline de transformations

**Objectif** : Combiner plusieurs transformations en s√©quence

```python
def niveau_2_pipeline():
    """Utilisation d'un pipeline de transformations multiples"""
    
    # Prompt initial simple
    prompt_analyse = Prompt(
        instruction="Analysez les risques de ce projet",
        context="Projet: Migration de 50 applications vers le cloud en 6 mois"
    )
    
    # Cr√©ation d'un pipeline de transformations
    pipeline_analyse = pipeline(
        make_formal,                                    # 1. Rendre formel
        add_confidence_scoring,                         # 2. Ajouter scoring confiance  
        lambda p: add_explanation_requirement(          # 3. Demander justifications
            p, "Justifiez chaque risque identifi√©:"
        )
    )
    
    # Application du pipeline
    prompt_enrichi = pipeline_analyse(prompt_analyse)
    
    print("=== PIPELINE DE TRANSFORMATIONS ===")
    print(prompt_enrichi.format())
    
    return prompt_enrichi
```

**üí° Points d'apprentissage :**
- `pipeline()` combine plusieurs transformations
- L'ordre des transformations compte
- Les lambda permettent de personnaliser les transformations

---

## üü† NIVEAU 3 : TEMPLATES AVANC√âS - Cas d'usage sp√©cialis√©s

### 3.1 Template Few-Shot Learning

**Objectif** : Cr√©er un syst√®me d'apprentissage par l'exemple

```python
def niveau_3_few_shot():
    """Template few-shot pour reconnaissance de patterns"""
    
    # Exemples pour apprendre un pattern de bug reports
    exemples_bugs = [
        (
            "L'app crash quand je clique sur 'Envoyer' apr√®s avoir tap√© un message long",
            "BUG: UI/UX | IMPACT: Bloquant | REPRO: Message >200 chars + bouton Envoyer | PRIORIT√â: Haute"
        ),
        (
            "Les images ne se chargent pas bien sur mobile, √ßa prend 30 secondes",
            "BUG: Performance | IMPACT: G√™nant | REPRO: Mobile + chargement images | PRIORIT√â: Moyenne"
        ),
        (
            "Impossible de se connecter depuis hier soir, erreur 500",
            "BUG: Backend | IMPACT: Critique | REPRO: Connexion utilisateur | PRIORIT√â: Critique"
        )
    ]
    
    # Template few-shot
    bug_classifier = few_shot_learning_template(
        task="classification et structuration de bug reports",
        examples=exemples_bugs,
        pattern_description="Format: TYPE | IMPACT | REPRODUCTION | PRIORIT√â"
    )
    
    # Enrichissement avec pipeline
    bug_enhanced = pipeline(
        add_confidence_scoring,
        lambda p: add_explanation_requirement(p, "Expliquez votre classification:")
    )(bug_classifier)
    
    print("=== FEW-SHOT BUG CLASSIFICATION ===")
    print(bug_enhanced.format())
    
    return bug_enhanced
```

### 3.2 Template Chain-of-Thought

**Objectif** : Prompt pour raisonnement √©tape par √©tape

```python
def niveau_3_chain_of_thought():
    """Template pour r√©solution de probl√®me complexe"""
    
    # Probl√®me business complexe
    problem_solver = chain_of_thought_template(
        problem_type="optimisation business",
        context="""
        Situation: Une startup SaaS (ARR: 2M‚Ç¨) constate:
        - Churn rate: 15% mensuel (industrie: 5-7%)
        - Customer Acquisition Cost: 800‚Ç¨ (LTV: 2400‚Ç¨)
        - Support tickets: +40% en 3 mois
        - √âquipe dev: surcharg√©e, v√©locit√© -30%
        
        Question: Quelle strat√©gie adopter en priorit√©?
        """
    )
    
    # Pipeline d'enrichissement pour analyse business
    business_pipeline = pipeline(
        lambda p: add_alternative_perspectives(p, 2),  # Perspectives alternatives
        lambda p: add_source_requirements(p, [         # Sources requises
            "m√©triques SaaS", "benchmarks secteur", "analyses churn"
        ]),
        add_confidence_scoring
    )
    
    problem_enhanced = business_pipeline(problem_solver)
    
    print("=== CHAIN-OF-THOUGHT BUSINESS ===")
    print(problem_enhanced.format())
    
    return problem_enhanced
```

**üí° Concepts avanc√©s :**
- Few-shot learning : l'IA apprend des patterns √† partir d'exemples
- Chain-of-thought : d√©composition du raisonnement en √©tapes
- Perspectives alternatives enrichissent l'analyse

---

## üî¥ NIVEAU 4 : ARCHITECTURES COMPLEXES - Syst√®mes multi-prompts

### 4.1 G√©n√©ration de variations pour A/B Testing

**Objectif** : Cr√©er plusieurs versions d'un prompt pour tester leur efficacit√©

```python
def niveau_4_variations_ab():
    """G√©n√©ration syst√©matique de variations pour tests A/B"""
    
    # Prompt de base pour customer success
    base_customer_success = Prompt(
        instruction="R√©digez un email de r√©activation pour un client inactif depuis 60 jours",
        context="""
        Client: PME utilisant notre CRM depuis 18 mois
        Derni√®re connexion: il y a 60 jours  
        Historique: Utilisateur actif puis arr√™t brutal
        Objectif: Identifier les blocages et proposer solutions
        """,
        constraints=[
            "Ton empathique mais professionnel",
            "Maximum 200 mots",
            "Call-to-action clair"
        ]
    )
    
    # Strat√©gies de variation diff√©rentes
    strategies_ab = [
        # Variation A: Approche directe
        lambda p: pipeline(
            make_formal,
            lambda p: add_explanation_requirement(p, "Utilisez une approche directe et factuelle")
        )(p),
        
        # Variation B: Approche empathique  
        lambda p: pipeline(
            lambda p: add_explanation_requirement(p, "Montrez de l'empathie et de la compr√©hension"),
            lambda p: add_alternative_perspectives(p, 1)
        )(p),
        
        # Variation C: Approche value-driven
        lambda p: pipeline(
            lambda p: add_explanation_requirement(p, "Mettez l'accent sur la valeur perdue"),
            add_confidence_scoring
        )(p),
        
        # Variation D: Approche socratique
        lambda p: pipeline(
            make_socratic,
            lambda p: add_explanation_requirement(p, "Posez des questions pour comprendre")
        )(p)
    ]
    
    # G√©n√©ration des variations
    variations = generate_variations(base_customer_success, strategies_ab)
    
    print("=== VARIATIONS POUR A/B TESTING ===")
    for i, variation in enumerate(variations, 1):
        print(f"\n--- VARIATION {chr(64+i)} ---")
        print(f"Strat√©gie: {['Directe', 'Empathique', 'Value-driven', 'Socratique'][i-1]}")
        print(variation.format()[:300] + "...")
        print(f"Valide: {'‚úì' if variation.validate() else '‚úó'}")
    
    return variations
```

### 4.2 Syst√®me multi-templates avec orchestration

**Objectif** : Combiner plusieurs templates pour un workflow complexe

```python
def niveau_4_workflow_complexe():
    """Workflow d'analyse compl√®te avec multiple templates"""
    
    print("=== WORKFLOW ANALYSE PRODUIT COMPLEXE ===")
    
    # √âTAPE 1: Analyse SWOT
    swot_analysis = structured_analysis_template(
        subject="Lancement d'une plateforme de formation IA pour entreprises",
        framework="Analyse SWOT",
        dimensions=["Forces", "Faiblesses", "Opportunit√©s", "Menaces"]
    )
    
    # √âTAPE 2: Sc√©narios de march√©
    market_scenarios = scenario_planning_template(
        situation="P√©n√©tration march√© formation IA entreprise",
        variables=["adoption IA", "budgets formation", "concurrence", "r√©glementation"],
        time_horizon="18 mois"
    )
    
    # √âTAPE 3: Comparaison concurrentielle  
    competitor_analysis = comparison_template(
        items=["Coursera Business", "LinkedIn Learning", "Udacity Enterprise"],
        aspects=["prix", "contenu IA", "certification", "int√©gration LMS", "support client"]
    )
    
    # √âTAPE 4: Plan d'action
    action_plan = role_play_template(
        role="directeur produit exp√©riment√©",
        scenario="Synth√®se des analyses pr√©c√©dentes pour d√©finir la roadmap produit",
        objectives=[
            "Prioriser les fonctionnalit√©s critiques",
            "Identifier les risques majeurs", 
            "D√©finir les m√©triques de succ√®s",
            "Planifier les 6 premiers mois"
        ]
    )
    
    # Pipeline d'enrichissement commun
    enrichment_pipeline = pipeline(
        make_formal,
        add_confidence_scoring,
        lambda p: add_source_requirements(p, ["√©tudes march√©", "benchmarks", "donn√©es clients"])
    )
    
    # Application du pipeline √† tous les templates
    workflow_prompts = {
        "swot": enrichment_pipeline(swot_analysis),
        "scenarios": enrichment_pipeline(market_scenarios), 
        "competition": enrichment_pipeline(competitor_analysis),
        "action_plan": enrichment_pipeline(action_plan)
    }
    
    # Affichage du workflow
    for step_name, prompt in workflow_prompts.items():
        print(f"\n{'='*20} √âTAPE: {step_name.upper()} {'='*20}")
        print(prompt.format()[:400] + "...\n")
        print(f"Validation: {'‚úì' if prompt.validate() else '‚úó'}")
    
    return workflow_prompts
```

**üí° Architecture avanc√©e :**
- Orchestration de multiples templates
- Pipeline r√©utilisable sur plusieurs prompts
- Workflow structur√© pour analyses complexes

---

## üü£ NIVEAU 5 : EXPERT - Gestion et optimisation

### 5.1 Syst√®me de sauvegarde et r√©utilisation

**Objectif** : Cr√©er une biblioth√®que de prompts r√©utilisables

```python
import json
from datetime import datetime

def niveau_5_bibliotheque_prompts():
    """Syst√®me avanc√© de gestion de biblioth√®que de prompts"""
    
    # Classe pour g√©rer une biblioth√®que
    class PromptLibrary:
        def __init__(self):
            self.prompts = {}
            self.metadata = {
                "created": datetime.now().isoformat(),
                "version": "1.0",
                "total_prompts": 0
            }
        
        def add_prompt(self, name, prompt, tags=None, description=""):
            """Ajoute un prompt √† la biblioth√®que"""
            self.prompts[name] = {
                "prompt_data": prompt.to_dict(),
                "tags": tags or [],
                "description": description,
                "created": datetime.now().isoformat(),
                "usage_count": 0
            }
            self.metadata["total_prompts"] = len(self.prompts)
        
        def get_prompt(self, name):
            """R√©cup√®re et instancie un prompt"""
            if name in self.prompts:
                self.prompts[name]["usage_count"] += 1
                return Prompt.from_dict(self.prompts[name]["prompt_data"])
            return None
        
        def search_by_tags(self, tags):
            """Recherche par tags"""
            results = []
            for name, data in self.prompts.items():
                if any(tag in data["tags"] for tag in tags):
                    results.append((name, data["description"]))
            return results
        
        def export_json(self, filename):
            """Export en JSON"""
            full_data = {
                "metadata": self.metadata,
                "prompts": self.prompts
            }
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(full_data, f, indent=2, ensure_ascii=False)
    
    # Cr√©ation de la biblioth√®que
    lib = PromptLibrary()
    
    # Ajout de prompts sp√©cialis√©s
    
    # 1. Prompt d'analyse de code
    code_analyzer = error_analysis_template(
        domain="Python/Django",
        error_types=["s√©curit√©", "performance", "maintenabilit√©", "bonnes pratiques"]
    )
    lib.add_prompt(
        "code_analyzer_python", 
        code_analyzer,
        tags=["d√©veloppement", "code", "python", "analyse"],
        description="Analyseur de code Python/Django complet"
    )
    
    # 2. G√©n√©rateur de documentation
    doc_generator = text_generation_template(
        style="technique documentaire",
        requirements=["Structure claire", "Exemples concrets", "API reference"],
        length_constraint="500-1000 mots"
    )
    lib.add_prompt(
        "doc_generator",
        doc_generator, 
        tags=["documentation", "technique", "API"],
        description="G√©n√©rateur de documentation technique"
    )
    
    # 3. Analyseur de sentiment client
    sentiment_classifier = few_shot_learning_template(
        task="analyse de sentiment client avanc√©e",
        examples=[
            ("Service rapide mais produit d√©cevant", "MITIGE: Service(+) Produit(-)"),
            ("Excellent support, r√©solution imm√©diate!", "POSITIF: Support(++) R√©solution(++)"), 
            ("Facturation confuse, j'abandonne", "NEGATIF: Process(-) Intention_exit")
        ],
        pattern_description="Sentiment global + d√©tail par aspect"
    )
    lib.add_prompt(
        "sentiment_analyzer_advanced",
        sentiment_classifier,
        tags=["client", "sentiment", "feedback", "analyse"],
        description="Analyse de sentiment client avec d√©tail par aspects"
    )
    
    print("=== BIBLIOTH√àQUE DE PROMPTS ===")
    print(f"Prompts cr√©√©s: {lib.metadata['total_prompts']}")
    
    # D√©monstration de recherche
    results = lib.search_by_tags(["analyse", "code"])
    print(f"\nRecherche 'analyse + code': {len(results)} r√©sultats")
    for name, desc in results:
        print(f"  - {name}: {desc}")
    
    # R√©utilisation d'un prompt
    retrieved_prompt = lib.get_prompt("code_analyzer_python")
    if retrieved_prompt:
        print(f"\nPrompt r√©cup√©r√© et utilisable:")
        print(f"Valid: {retrieved_prompt.validate()}")
        
        # Modification pour nouveau contexte
        retrieved_prompt.context = "Code Django avec vuln√©rabilit√© potentielle CSRF"
        print("Prompt adapt√© pour nouveau contexte ‚úì")
    
    # Export de la biblioth√®que
    lib.export_json("ma_bibliotheque_prompts.json")
    print("\nBiblioth√®que export√©e en JSON ‚úì")
    
    return lib
```

### 5.2 M√©triques et optimisation de prompts

**Objectif** : Mesurer et optimiser la performance des prompts

```python
def niveau_5_optimisation():
    """Syst√®me de m√©triques et d'optimisation de prompts"""
    
    class PromptOptimizer:
        def __init__(self):
            self.metrics = {}
        
        def analyze_prompt_quality(self, prompt, name):
            """Analyse la qualit√© d'un prompt selon plusieurs crit√®res"""
            metrics = {
                "clarity_score": self._calculate_clarity(prompt),
                "complexity_score": self._calculate_complexity(prompt), 
                "completeness_score": self._calculate_completeness(prompt),
                "reusability_score": self._calculate_reusability(prompt)
            }
            
            # Score global
            metrics["overall_score"] = sum(metrics.values()) / len(metrics)
            self.metrics[name] = metrics
            return metrics
        
        def _calculate_clarity(self, prompt):
            """Score de clart√© (0-10)"""
            score = 5.0
            
            # Instruction claire et sp√©cifique
            if len(prompt.instruction) > 20:
                score += 1
            if any(verb in prompt.instruction.lower() for verb in 
                  ["analyze", "generate", "classify", "compare", "explain"]):
                score += 1
                
            # Contraintes d√©finies
            if prompt.constraints:
                score += 1
                
            # Format de sortie sp√©cifi√©
            if prompt.output_format:
                score += 1
                
            return min(10, score)
        
        def _calculate_complexity(self, prompt):
            """Score de complexit√© appropri√©e (0-10)"""
            score = 5.0
            
            # √âquilibre des √©l√©ments
            total_elements = len(prompt.constraints) + len(prompt.examples)
            if 2 <= total_elements <= 8:
                score += 2
            elif total_elements > 8:
                score -= 1  # Trop complexe
                
            # Contexte appropri√©
            if prompt.context and len(prompt.context) < 500:
                score += 1
                
            return min(10, score)
        
        def _calculate_completeness(self, prompt):
            """Score de compl√©tude (0-10)"""
            score = 0
            
            # √âl√©ments essentiels
            if prompt.instruction: score += 3
            if prompt.context: score += 2
            if prompt.constraints: score += 2
            if prompt.examples: score += 2
            if prompt.output_format: score += 1
            
            return min(10, score)
        
        def _calculate_reusability(self, prompt):
            """Score de r√©utilisabilit√© (0-10)"""
            score = 5.0
            
            # G√©n√©ricit√© vs sp√©cificit√©
            if prompt.context and "{{" in prompt.context:  # Variables
                score += 2
            if len(prompt.examples) >= 2:
                score += 1
            if prompt.metadata:
                score += 1
                
            return min(10, score)
        
        def suggest_improvements(self, prompt, metrics):
            """Suggestions d'am√©lioration bas√©es sur les m√©triques"""
            suggestions = []
            
            if metrics["clarity_score"] < 7:
                suggestions.append("Clarifier l'instruction avec des verbes d'action sp√©cifiques")
                suggestions.append("Ajouter un format de sortie d√©taill√©")
            
            if metrics["completeness_score"] < 7:
                suggestions.append("Ajouter des exemples concrets")
                suggestions.append("D√©finir des contraintes plus pr√©cises")
            
            if metrics["reusability_score"] < 6:
                suggestions.append("G√©n√©raliser le contexte avec des variables")
                suggestions.append("Ajouter des m√©tadonn√©es pour le catalogage")
            
            return suggestions
    
    # Test du syst√®me d'optimisation
    optimizer = PromptOptimizer()
    
    # Prompt √† optimiser
    prompt_test = Prompt(
        instruction="Faire quelque chose avec ce texte",  # Volontairement vague
        context="Un texte quelconque"
    )
    
    print("=== ANALYSE DE QUALIT√â ===")
    metrics = optimizer.analyze_prompt_quality(prompt_test, "prompt_vague")
    
    for metric, score in metrics.items():
        print(f"{metric}: {score:.1f}/10")
    
    # Suggestions d'am√©lioration
    suggestions = optimizer.suggest_improvements(prompt_test, metrics)
    print(f"\n=== SUGGESTIONS D'AM√âLIORATION ===")
    for i, suggestion in enumerate(suggestions, 1):
        print(f"{i}. {suggestion}")
    
    # Version am√©lior√©e
    prompt_ameliore = classification_template(
        categories=["Technique", "Business", "Cr√©atif"],
        description="Classification de contenus selon leur nature",
        examples=[
            ("Documentation API REST", "Technique"),
            ("Plan marketing Q4", "Business"), 
            ("Brainstorming noms produit", "Cr√©atif")
        ]
    )
    
    print(f"\n=== APR√àS AM√âLIORATION ===")
    metrics_ameliore = optimizer.analyze_prompt_quality(prompt_ameliore, "prompt_ameliore")
    for metric, score in metrics_ameliore.items():
        print(f"{metric}: {score:.1f}/10")
    
    return optimizer

```

---

## üìã R√âCAPITULATIF ET BONNES PRATIQUES

### Progression recommand√©e :

1. **üü¢ Niveau 1** : Ma√Ætrisez la cr√©ation manuelle et les templates simples
2. **üü° Niveau 2** : Explorez les transformations et pipelines  
3. **üü† Niveau 3** : Utilisez les templates avanc√©s (few-shot, chain-of-thought)
4. **üî¥ Niveau 4** : Orchestrez des workflows complexes
5. **üü£ Niveau 5** : Optimisez et g√©rez vos biblioth√®ques de prompts

### Conseils d'expert :

‚úÖ **Toujours valider** vos prompts avec `validate()`  
‚úÖ **Tester en conditions r√©elles** avant de d√©ployer  
‚úÖ **Documenter vos templates** r√©utilisables  
‚úÖ **Mesurer la performance** avec des m√©triques  
‚úÖ **It√©rer et am√©liorer** continuellement  

### Patterns √† retenir :

- **Pipeline > Transformation unique** : Combinez toujours plusieurs am√©liorations
- **Template + Pipeline** : Partez d'un template et enrichissez-le
- **Few-shot > Zero-shot** : Les exemples am√©liorent drastiquement la qualit√©
- **Validation syst√©matique** : Un prompt non valid√© est un risque

---

## üöÄ ALLER PLUS LOIN

Une fois ces concepts ma√Ætris√©s, vous pouvez :

- Cr√©er vos propres transformations personnalis√©es
- D√©velopper des templates m√©tier sp√©cifiques
- Int√©grer des APIs pour l'√©valuation automatique  
- Construire des interfaces utilisateur pour vos prompts
- Impl√©menter des syst√®mes de versioning avanc√©s

Le Toolkit PET vous donne toutes les briques pour devenir un expert en Prompt Engineering ! üéØ